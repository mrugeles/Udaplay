{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport importlib.util\\nimport sys\\n\\n# Check if \\'pysqlite3\\' is available before importing\\nif importlib.util.find_spec(\"pysqlite3\") is not None:\\n    import pysqlite3\\n    sys.modules[\\'sqlite3\\'] = sys.modules.pop(\\'pysqlite3\\')\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\"\"\"\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs\n",
    "# For example: \n",
    "import os\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.rag import RAG\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage, BaseMessage\n",
    "from lib.tooling import tool\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from lib.evaluation import TestCase, AgentEvaluator, EvaluationResult, EvaluationReport\n",
    "from typing import List, Dict\n",
    "from tavily import TavilyClient\n",
    "from lib.parsers import PydanticOutputParser\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08ee9ccc-e702-4b40-98fd-b42049fcf711",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "\n",
    "embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    api_base=\"https://openai.vocareum.com/v1\")\n",
    "\n",
    "collection = chroma_client.get_collection(\"udaplay\", embedding_function=embedding_fn)\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "retrieve_game_rag = RAG(\n",
    "    llm=rag_llm,\n",
    "    vector_store = collection\n",
    ")\n",
    "@tool\n",
    "def retrieve_game(query):\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "    args:\n",
    "    - query: a question about game industry. \n",
    "    \"\"\"\n",
    "    result:Run = retrieve_game_rag.invoke(query)\n",
    "    return result.get_final_state()[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: List[str]) -> EvaluationReport:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    The result includes:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "    llm_judge = LLM(model=\"gpt-4o-mini\")\n",
    "    docs_text = \"\\n\\n\".join(retrieved_docs) if retrieved_docs else \"No documents provided.\"\n",
    "    prompt = (\n",
    "        \"Your task is to evaluate if the documents are enough to respond the query.\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Documents:\\n{docs_text}\\n\"\n",
    "        \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "    )\n",
    "\n",
    "    response = llm_judge.invoke(prompt, response_format=EvaluationReport)\n",
    "    parser = PydanticOutputParser(model_class=EvaluationReport)\n",
    "    try:\n",
    "        report = parser.parse(response)\n",
    "    except Exception as e:\n",
    "        report = EvaluationReport(useful=False, description=f\"Failed to parse judge response: {e}\")\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. \n",
    "\n",
    "@tool\n",
    "def game_web_search(query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Search the web using Tavily API\n",
    "    args:\n",
    "        query (str): Search query\n",
    "    \"\"\"\n",
    "    client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "    \n",
    "    # Perform the search\n",
    "    search_result = client.search(\n",
    "        query=query,\n",
    "        include_answer=True,\n",
    "        include_raw_content=False,\n",
    "        include_images=False\n",
    "    )\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = {\n",
    "        \"answer\": search_result.get(\"answer\", \"\"),\n",
    "        \"results\": search_result.get(\"results\", []),\n",
    "        \"search_metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "\n",
    "\n",
    "agent_instructions = (\n",
    "    \"You are UdaPlay, an AI research assistant focused on video games.\\n\"\n",
    "    \"Use the available tools to answer questions with verified information.\\n\"\n",
    "    \"1. Call `retrieve_game` to search internal knowledge.\\n\"\n",
    "    \"2. Always call `evaluate_retrieval` with the user's question and the retrieved documents.\\n\"\n",
    "    \"3. If the evaluation result indicates the documents are not useful, call `game_web_search`.\\n\"\n",
    "    \"4. Combine information from all useful sources, cite them, and provide a confidence score between 0 and 1.\\n\"\n",
    "    \"5. Present the final answer in a clear, natural format.\"\n",
    ")\n",
    "\n",
    "udaplay_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=agent_instructions,\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    "    temperature=0.3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?\n",
    "def print_messages(messages: List[BaseMessage]):\n",
    "    for m in messages:\n",
    "        print(f\" -> (role = {m.role}, content = {m.content}, tool_calls = {getattr(m, 'tool_calls', None)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "841847d7-3c7f-4bbf-a5bb-40e5069e8228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      " -> (role = system, content = You are UdaPlay, an AI research assistant focused on video games.\n",
      "Use the available tools to answer questions with verified information.\n",
      "1. Call `retrieve_game` to search internal knowledge.\n",
      "2. Always call `evaluate_retrieval` with the user's question and the retrieved documents.\n",
      "3. If the evaluation result indicates the documents are not useful, call `game_web_search`.\n",
      "4. Combine information from all useful sources, cite them, and provide a confidence score between 0 and 1.\n",
      "5. Present the final answer in a clear, natural format., tool_calls = None)\n",
      " -> (role = user, content = When Pokémon Gold and Silver was released?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_lLFtiY6pTVwapMJ9Ex2Mii3m', function=Function(arguments='{\"query\":\"Pokémon Gold and Silver release date\"}', name='retrieve_game'), type='function')])\n",
      " -> (role = tool, content = \"Pok\\u00e9mon Gold and Silver were released in 1999.\", tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_LCPwaoqw3rKePOxO4qwYC1Of', function=Function(arguments='{\"question\":\"When Pokémon Gold and Silver was released?\",\"retrieved_docs\":[\"Pokémon Gold and Silver were released in 1999.\"]}', name='evaluate_retrieval'), type='function')])\n",
      " -> (role = tool, content = \"useful=True description='The document provides a clear and direct answer to the question regarding the release date of Pok\\u00e9mon Gold and Silver. It states that the games were released in 1999, which is sufficient information to respond to the query. There are no additional details required to understand the context of the release date, making the document useful for answering the question.'\", tool_calls = None)\n",
      " -> (role = assistant, content = Pokémon Gold and Silver were released in 1999. This information is accurate and directly answers your question. Confidence score: 1.0., tool_calls = None)\n"
     ]
    }
   ],
   "source": [
    "run1 = udaplay_agent.invoke(\"When Pokémon Gold and Silver was released?\")\n",
    "messages = run1.get_final_state()[\"messages\"]\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4a92c4b-1dea-4f27-9ba1-f3c2fd12a0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      " -> (role = system, content = You are UdaPlay, an AI research assistant focused on video games.\n",
      "Use the available tools to answer questions with verified information.\n",
      "1. Call `retrieve_game` to search internal knowledge.\n",
      "2. Always call `evaluate_retrieval` with the user's question and the retrieved documents.\n",
      "3. If the evaluation result indicates the documents are not useful, call `game_web_search`.\n",
      "4. Combine information from all useful sources, cite them, and provide a confidence score between 0 and 1.\n",
      "5. Present the final answer in a clear, natural format., tool_calls = None)\n",
      " -> (role = user, content = When Pokémon Gold and Silver was released?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_lLFtiY6pTVwapMJ9Ex2Mii3m', function=Function(arguments='{\"query\":\"Pokémon Gold and Silver release date\"}', name='retrieve_game'), type='function')])\n",
      " -> (role = tool, content = \"Pok\\u00e9mon Gold and Silver were released in 1999.\", tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_LCPwaoqw3rKePOxO4qwYC1Of', function=Function(arguments='{\"question\":\"When Pokémon Gold and Silver was released?\",\"retrieved_docs\":[\"Pokémon Gold and Silver were released in 1999.\"]}', name='evaluate_retrieval'), type='function')])\n",
      " -> (role = tool, content = \"useful=True description='The document provides a clear and direct answer to the question regarding the release date of Pok\\u00e9mon Gold and Silver. It states that the games were released in 1999, which is sufficient information to respond to the query. There are no additional details required to understand the context of the release date, making the document useful for answering the question.'\", tool_calls = None)\n",
      " -> (role = assistant, content = Pokémon Gold and Silver were released in 1999. This information is accurate and directly answers your question. Confidence score: 1.0., tool_calls = None)\n",
      " -> (role = user, content = Which one was the first 3D platformer Mario game?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_63uvgaNthOxfSv2YVrXLR5pN', function=Function(arguments='{\"query\":\"first 3D platformer Mario game\"}', name='retrieve_game'), type='function')])\n",
      " -> (role = tool, content = \"The first 3D platformer Mario game is Super Mario 64, released in 1996 for the Nintendo 64.\", tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_ha5w9WbYjW5aEkNo5WWbrYHV', function=Function(arguments='{\"question\":\"Which one was the first 3D platformer Mario game?\",\"retrieved_docs\":[\"The first 3D platformer Mario game is Super Mario 64, released in 1996 for the Nintendo 64.\"]}', name='evaluate_retrieval'), type='function')])\n",
      " -> (role = tool, content = \"useful=True description=\\\"The document provides a clear and direct answer to the question by stating that 'Super Mario 64' is the first 3D platformer Mario game, along with its release year and the platform it was released on. This information is sufficient to respond to the query accurately.\\\"\", tool_calls = None)\n",
      " -> (role = assistant, content = The first 3D platformer Mario game is **Super Mario 64**, which was released in 1996 for the Nintendo 64. This information is accurate and directly addresses your question. Confidence score: 1.0., tool_calls = None)\n"
     ]
    }
   ],
   "source": [
    "run2 = udaplay_agent.invoke(\"Which one was the first 3D platformer Mario game?\")\n",
    "messages = run2.get_final_state()[\"messages\"]\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "081fda3e-5889-4edf-97fc-7da486f90051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      " -> (role = system, content = You are UdaPlay, an AI research assistant focused on video games.\n",
      "Use the available tools to answer questions with verified information.\n",
      "1. Call `retrieve_game` to search internal knowledge.\n",
      "2. Always call `evaluate_retrieval` with the user's question and the retrieved documents.\n",
      "3. If the evaluation result indicates the documents are not useful, call `game_web_search`.\n",
      "4. Combine information from all useful sources, cite them, and provide a confidence score between 0 and 1.\n",
      "5. Present the final answer in a clear, natural format., tool_calls = None)\n",
      " -> (role = user, content = When Pokémon Gold and Silver was released?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_lLFtiY6pTVwapMJ9Ex2Mii3m', function=Function(arguments='{\"query\":\"Pokémon Gold and Silver release date\"}', name='retrieve_game'), type='function')])\n",
      " -> (role = tool, content = \"Pok\\u00e9mon Gold and Silver were released in 1999.\", tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_LCPwaoqw3rKePOxO4qwYC1Of', function=Function(arguments='{\"question\":\"When Pokémon Gold and Silver was released?\",\"retrieved_docs\":[\"Pokémon Gold and Silver were released in 1999.\"]}', name='evaluate_retrieval'), type='function')])\n",
      " -> (role = tool, content = \"useful=True description='The document provides a clear and direct answer to the question regarding the release date of Pok\\u00e9mon Gold and Silver. It states that the games were released in 1999, which is sufficient information to respond to the query. There are no additional details required to understand the context of the release date, making the document useful for answering the question.'\", tool_calls = None)\n",
      " -> (role = assistant, content = Pokémon Gold and Silver were released in 1999. This information is accurate and directly answers your question. Confidence score: 1.0., tool_calls = None)\n",
      " -> (role = user, content = Which one was the first 3D platformer Mario game?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_63uvgaNthOxfSv2YVrXLR5pN', function=Function(arguments='{\"query\":\"first 3D platformer Mario game\"}', name='retrieve_game'), type='function')])\n",
      " -> (role = tool, content = \"The first 3D platformer Mario game is Super Mario 64, released in 1996 for the Nintendo 64.\", tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_ha5w9WbYjW5aEkNo5WWbrYHV', function=Function(arguments='{\"question\":\"Which one was the first 3D platformer Mario game?\",\"retrieved_docs\":[\"The first 3D platformer Mario game is Super Mario 64, released in 1996 for the Nintendo 64.\"]}', name='evaluate_retrieval'), type='function')])\n",
      " -> (role = tool, content = \"useful=True description=\\\"The document provides a clear and direct answer to the question by stating that 'Super Mario 64' is the first 3D platformer Mario game, along with its release year and the platform it was released on. This information is sufficient to respond to the query accurately.\\\"\", tool_calls = None)\n",
      " -> (role = assistant, content = The first 3D platformer Mario game is **Super Mario 64**, which was released in 1996 for the Nintendo 64. This information is accurate and directly addresses your question. Confidence score: 1.0., tool_calls = None)\n",
      " -> (role = user, content = Was Mortal Kombat X realeased for Playstation 5?, tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_MMppEyKpzq01Hp1NyDlfNMhs', function=Function(arguments='{\"query\":\"Mortal Kombat X release for Playstation 5\"}', name='retrieve_game'), type='function')])\n",
      " -> (role = tool, content = \"I don't know.\", tool_calls = None)\n",
      " -> (role = assistant, content = None, tool_calls = [ChatCompletionMessageToolCall(id='call_TPuXfhkqq5ykAxGqhYJOtmld', function=Function(arguments='{\"query\":\"Mortal Kombat X release for Playstation 5\"}', name='game_web_search'), type='function')])\n",
      " -> (role = tool, content = \"{'answer': 'Mortal Kombat X was originally released for PlayStation 4 in 2015. It is not natively available for PlayStation 5 but can be played with updates. PS5 compatibility requires the latest system software.', 'results': [{'url': 'https://www.youtube.com/watch?v=HUNMZwDdrvY', 'title': 'Mortal Kombat X (PS5) 4K 60FPS HDR Gameplay - YouTube', 'content': 'Mortal Kombat X (PS5) 4K 60FPS HDR Gameplay\\\\nDieison Games\\\\n153000 subscribers\\\\n44 likes\\\\n2104 views\\\\n29 Jul 2023\\\\nMortal Kombat X (PS5) 4K 60FPS HDR Gameplay\\\\n\\\\nMortal Kombat X[b]\\\\xa0is a 2015\\\\xa0fighting game\\\\xa0developed by\\\\xa0NetherRealm Studios\\\\xa0and published by\\\\xa0Warner Bros. Interactive Entertainment\\\\xa0for\\\\xa0Windows,\\\\xa0PlayStation 4, and\\\\xa0Xbox One. It is the tenth main installment in the\\\\xa0Mortal Kombat\\\\xa0series and a sequel to\\\\xa0Mortal Kombat\\\\xa0(2011), taking place 25 years later after the events of its predecessor.\\\\xa0High Voltage Software\\\\xa0developed the Windows version of the game, with Polish studio QLOC taking over the work on it shortly after the release of Kombat Pack 1.\\\\n\\\\n\\u25b6TikTok @dieisongames\\\\nhttps://www.tiktok.com/@dieisongames1\\\\n\\u25b6Insta @dieisongames\\\\nhttps://www.instagram.com/dieisongames\\\\n\\u25b62\\u00ba Channel\\\\nhttps://www.youtube.com/dieisongt \\\\n\\\\nMortal Kombat X (PS5) 4K 60FPS HDR Gameplay\\\\nMortal Kombat X 4k Gameplay PS5\\\\n\\\\n#MortalKombatX #ps5 #playstation5 #ps5version \\\\n\\\\n-~-~~-~~~-~~-~-\\\\nPlease watch: \\\"Gran Turismo 7 (PS5) 4K 60FPS HDR Gameplay (Tomahawk 645 km/h)\\\"\\\\nhttps://youtu.be/hy0Q-ieNnMQ\\\\n-~-~~-~~~-~~-~-\\\\n2 comments\\\\n', 'score': 0.79769903, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Mortal_Kombat_X', 'title': 'Mortal Kombat X - Wikipedia', 'content': 'Release. Mortal Kombat X was released worldwide (except Germany) for PC, PlayStation 4, and Xbox One on April 14, 2015. For reasons relating to the initial', 'score': 0.7548612, 'raw_content': None}, {'url': 'https://store.playstation.com/en-us/product/UP1018-CUSA00967_00-MORTALKOMBATX000', 'title': 'Mortal Kombat X - PlayStation Store', 'content': 'Mortal Kombat X Access Denied Access Denied You don\\\\'t have permission to access \\\" on this server. To play this game on PS5, your system may need to be updated to the latest system software. See PlayStation.com/bc for more details. Online features require an account and are subject to terms of service and applicable privacy policy (playstationnetwork.com/terms-of-service & playstationnetwork.com/privacy-policy). Software subject to license (us.playstation.com/softwarelicense). \\\\'MORTAL KOMBAT X software \\u00a9 2015 Warner Bros. Entertainment Inc. Developed by NetherRealm Studios. WB GAMES LOGO, WB SHIELD, NETHERREALM LOGO, MORTAL KOMBAT, THE DRAGON LOGO, and all related characters and elements are trademarks of and \\u00a9 Warner Bros. Entertainment Inc. PlayStation Studios PS Store Cancellation Policy Android App iOS App \\u00a9 2025 Sony Interactive Entertainment LLC', 'score': 0.6762998, 'raw_content': None}, {'url': 'https://mortalkombat.fandom.com/wiki/Mortal_Kombat_X', 'title': 'Mortal Kombat X', 'content': 'The current-generation console versions were released on April 14, 2015. Serving as both a follow-up and sequel to Mortal Kombat (2011), it follows the events', 'score': 0.66699636, 'raw_content': None}, {'url': 'https://www.playstation.com/en-us/games/mortal-kombat-x/', 'title': 'Mortal Kombat X - PS4 Games | PlayStation (US)', 'content': 'Mortal Kombat X - PS4 Games | PlayStation (US)  *   PS5 *   PS4 *   PS5 PS5   *   PS5 *   PS4 PS4   *   PS5 entertainment *   PS4 entertainment *   PS5 controllers *   Buy a PS5 PS4 Rating and Reviews 121121 ratings ### Report Review ### Report Review Report Review Rate;) Your Rating  ### No ratings and reviews. Be the first to add a rating and review To play this game on PS5, your system may need to be updated to the latest system software. Online features require an account and are subject to terms of service and applicable privacy policy (playstationnetwork.com/terms-of-service & playstationnetwork.com/privacy-policy). *    Mortal Kombat X - PS4 Games | PlayStation   *   PS5 *   PS4 Back to PlayStation Back to PlayStation', 'score': 0.6307082, 'raw_content': None}], 'search_metadata': {'timestamp': '2025-08-23T09:51:51.732108', 'query': 'Mortal Kombat X release for Playstation 5'}}\", tool_calls = None)\n",
      " -> (role = assistant, content = Mortal Kombat X was originally released for PlayStation 4 in 2015. It is not natively available for PlayStation 5, but it can be played on the PS5 with updates to the system software. Therefore, while you can play Mortal Kombat X on a PS5, it is not a dedicated PS5 release. \n",
      "\n",
      "Confidence score: 0.9., tool_calls = None)\n"
     ]
    }
   ],
   "source": [
    "run3 = udaplay_agent.invoke(\"Was Mortal Kombat X realeased for Playstation 5?\")\n",
    "messages = run3.get_final_state()[\"messages\"]\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
